{"cells":[{"cell_type":"markdown","metadata":{"id":"B-otENzYreQx"},"source":["# Bert"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15265,"status":"ok","timestamp":1669702811323,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"lnJNjEMJreQ0"},"outputs":[],"source":["# Import\n","import pandas as pd\n","import nltk\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import BertTokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report as clsr\n","from sklearn.metrics import confusion_matrix, cohen_kappa_score, plot_confusion_matrix\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.manifold import TSNE"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1669702811323,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"w6eI3SAFreQ2"},"outputs":[],"source":["df = pd.read_csv(\"../data/all_clean.csv\")\n","text=df['text']\n","sp500_mean_label=df['sp500_mean_label']\n","sp500_last_label=df['sp500_last_label']\n","usdx_mean_label=df['usdx_mean_label']\n","usdx_last_label=df['usdx_last_label']"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669702811323,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"70fXECPvreQ2"},"outputs":[],"source":["label_to_index = {}\n","index_to_label = {}\n","label_list = list(set(usdx_mean_label))\n","for i in range(len(label_list)):\n","    label = label_list[i]\n","    label_to_index[label] = i\n","    index_to_label[i] = label"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5198,"status":"ok","timestamp":1669702816518,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"0b8k161preQ3"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","input_ids = []\n","for text in text:\n","    encoded_sent = tokenizer.encode(text,\n","                                    add_special_tokens=True, \n","                                    max_length=128,\n","                                    truncation=True)\n","    input_ids.append(encoded_sent)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":307,"status":"ok","timestamp":1669702816820,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"61cEzKYFreQ3"},"outputs":[],"source":["input_ids = pad_sequences(input_ids, maxlen=128, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1238,"status":"ok","timestamp":1669702817752,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"KmYd7S6RreQ4"},"outputs":[],"source":["attention_masks = []\n","for sent in input_ids:\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    attention_masks.append(att_mask)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1669702817752,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"VXc8-z-9reQ5"},"outputs":[],"source":["labels = [label_to_index[label] for label in usdx_mean_label]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1669702817753,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"mh-ObTjKreQ5"},"outputs":[],"source":["train_input_ids, test_input_ids, train_labels, test_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\n","train_attention_masks, test_attention_masks, train_labels, test_labels = train_test_split(attention_masks, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669702817753,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"E6ZoDo7BreQ6"},"outputs":[],"source":["train_input_ids = torch.tensor(train_input_ids)\n","test_input_ids = torch.tensor(test_input_ids)\n","\n","train_labels = torch.tensor(train_labels)\n","test_labels = torch.tensor(test_labels)\n","\n","train_attention_masks = torch.tensor(train_attention_masks)\n","test_attention_masks = torch.tensor(test_attention_masks)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669702817753,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"JQPOERxFreQ7"},"outputs":[],"source":["batch_size = 32\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our test set.\n","test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12025,"status":"ok","timestamp":1669702829772,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"PkGJ9G6xreQ7","outputId":"fbd22a0c-18ef-4ed6-ec32-d313b4667262"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", \n","    num_labels = len(label_list),  \n","    output_attentions = False, \n","    output_hidden_states = False\n",")\n","model.cuda()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1669702829773,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"2-JRL5zvreQ8","outputId":"b8c17252-6788-4641-b382-f2935195feb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU\n"]}],"source":["device = torch.device(\"cpu\")\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU')\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1669702829773,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"Oq9lwX7WreQ8","outputId":"35d72452-6cfb-4e76-d217-7bb6b9e8b555"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 1e-5,\n","                  eps = 1e-8)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1669702829774,"user":{"displayName":"Ningyuan Zhou","userId":"01078915313981839350"},"user_tz":300},"id":"S0AIGP_nreQ9"},"outputs":[],"source":["dim_reducer = TSNE(n_components=2)\n","\n","def visualize_layerwise_embeddings(hidden_states,masks,labels,epoch,title,layers_to_visualize):\n","\n","    !mkdir -p /tmp/plots/{title}\n","    num_layers = len(layers_to_visualize)\n","    \n","    fig = plt.figure(figsize=(30,20)) #each subplot of size 6x6, each row will hold 4 plots\n","    title_name = \"Epoch \"+str(epoch)+\" Embeddings\"\n","    plt.suptitle(title_name, fontsize = 30, y = 0.92)\n","    labels = labels.numpy().reshape(-1)\n","    #Pic = pd.DataFrame()\n","    for i,layer_i in enumerate(layers_to_visualize):\n","        layer_embeds = hidden_states[layer_i]\n","        \n","        layer_averaged_hidden_states = torch.div(layer_embeds.sum(dim=1),masks.sum(dim=1,keepdim=True))\n","        layer_dim_reduced_embeds = dim_reducer.fit_transform(layer_averaged_hidden_states.detach().numpy())\n","        \n","        df = pd.DataFrame.from_dict({'x':layer_dim_reduced_embeds[:,0],'y':layer_dim_reduced_embeds[:,1],'label':labels})\n","        #Pic = pd.concat([Pic,df],ignore_index = True)\n","        \n","        fig = plt.subplot(331+i)\n","        plt.subplots_adjust(wspace =0.4, hspace =0.4)\n","        sns.scatterplot(data=df,x='x',y='y',hue='label')\n","        name = \"layer \"+str(layer_i+1)\n","        plt.title(name, fontsize = 20)\n","        \n","    #sns.scatterplot(data=Pic,x='x',y='y',hue='label')\n","    plt.savefig('vis'+str(epoch)+'.png')    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oX9O8HpIreQ9","outputId":"139b7021-2894-4d9b-f192-8788fbc8d405"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 29/168 [00:48<07:24,  3.20s/it]"]}],"source":["from tqdm import tqdm\n","\n","average_loss = []\n","for epoch_i in range(10):\n","    print(\"\")\n","    print('Epoch {}'.format(epoch_i + 1))\n","    print('Training...')\n","    \n","    total_loss = 0\n","    model.train()\n","\n","    train_masks,train_ys = torch.zeros(0,128),torch.zeros(0,1)\n","    train_hidden_states = None\n","\n","    progress = tqdm(range(len(train_dataloader)), position = 0)\n","\n","    for batch in train_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        model.zero_grad()\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask, \n","                        labels=b_labels,\n","                        output_hidden_states=True,\n","                        return_dict=True)\n","        \n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        hidden_states = outputs.hidden_states[1:]\n","        train_masks = torch.cat([train_masks,b_input_mask.cpu()])\n","        train_ys = torch.cat([train_ys,b_labels.cpu().view(-1,1)])\n","        \n","        if type(train_hidden_states) == type(None):\n","          train_hidden_states = tuple(layer_hidden_states.cpu() for layer_hidden_states in hidden_states)\n","        else:\n","          train_hidden_states = tuple(torch.cat([layer_hidden_state_all,layer_hidden_state_batch.cpu()])for layer_hidden_state_all,layer_hidden_state_batch in zip(train_hidden_states,hidden_states))\n","        \n","        progress.update(1)\n","        \n","    avg_train_loss = total_loss / len(train_dataloader)\n","    average_loss.append(avg_train_loss)\n","    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","    visualize_layerwise_embeddings(hidden_states=train_hidden_states,\n","                                 masks=train_masks,\n","                                 labels=train_ys,\n","                                 epoch=epoch_i,\n","                                 title='train_data',\n","                                 layers_to_visualize=[0,1,2,3,4,8,9,10,11])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imGoMWpcreQ-"},"outputs":[],"source":["model.eval()\n","preds_test = []\n","labels_test = []\n","for batch in test_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","    with torch.no_grad():\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    preds_flat = np.argmax(logits, axis=1).flatten()\n","    labels_flat = label_ids.flatten()\n","    \n","    preds_test += list(preds_flat)\n","    labels_test += list(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJfY0avnreQ-"},"outputs":[],"source":["print(\"Accuracy:\", accuracy_score(labels_test, preds_test))\n","print(\"Precision:\", precision_score(labels_test, preds_test, average=\"macro\"))\n","print(\"Recall:\", recall_score(labels_test, preds_test, average=\"macro\"))\n","print(\"Macro F1:\", f1_score(labels_test, preds_test, average=\"macro\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(average_loss, \"-ob\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Average Loss\")\n","plt.sivefig('avgloss.png')\n","\n","pd.DataFrame(average_loss).to_csv(\"avgloss.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jPLef6rreQ-"},"outputs":[],"source":["labels_test_txt = list(map(lambda x: index_to_label[x], labels_test))\n","preds_test_txt = list(map(lambda x: index_to_label[x], preds_test))\n","\n","def plot_matrix(y_true,y_pred, title=''):\n","    cf_matrix= confusion_matrix(y_true, y_pred)\n","    group_names = ['True Neg','False Pos','False Neg','True Pos']\n","    group_counts = [\"{0:0.0f}\".format(value) for value in\n","                cf_matrix.flatten()]\n","    group_percentages = [\"{0:.2%}\".format(value) for value in\n","                     cf_matrix.flatten()/np.sum(cf_matrix)]\n","    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n","          zip(group_names,group_counts,group_percentages)]\n","    labels = np.asarray(labels).reshape(2,2)\n","    ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues').set(title = title)\n","    plt.savefig('cfm'+'.png')  \n","    \n","    return ax\n","\n","\n","cnf_matrix = plot_matrix(labels_test_txt, preds_test_txt, labels=[0, 1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG7E5A9oreQ-"},"outputs":[],"source":["plt.grid(False)\n","#mat = confusion_matrix(y_test, nb_labels, labels=['Extremely Popular', 'Very Popular'])\n","\n","#plt.figure(figsize=(10, 8))\n","sns.heatmap(cnf_matrix.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=['Down', 'Up'],\n","            yticklabels=['Down', 'Up'], cmap = 'summer_r')\n","plt.xlabel('true label')\n","plt.ylabel('predicted label')\n","plt.savefig('reddit-nb-cm.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ra_-XbuOreQ-"},"outputs":[],"source":["print(clsr(labels_test, preds_test, target_names=['Down', 'Up']))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('anly-580')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"4a9e89f28feb74039ab2b7786a61f976ac4a753cf39b0d02488b88e6a82fd3ce"}}},"nbformat":4,"nbformat_minor":0}
